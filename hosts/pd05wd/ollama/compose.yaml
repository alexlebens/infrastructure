---
services:
    tailscale-ollama:
        image: ghcr.io/tailscale/tailscale:latest
        container_name: tailscale-ollama
        cap_add:
            - net_admin
            - sys_module
        environment:
            - TS_STATE_DIR=/var/lib/tailscale
            - TS_ENABLE_METRICS=true
            - TS_HOSTNAME=ollama-pd05wd
        env_file:
            - .ts-env
        labels:
            - "com.centurylinklabs.watchtower.scope=ollama"
        network_mode: service:ollama
        restart: always
        volumes:
            - tailscale:/var/lib/tailscale
        devices:
            - /dev/net/tun:/dev/net/tun

    watchtower:
        image: ghcr.io/containrrr/watchtower:latest
        container_name: ollama-watchtower
        command: --scope ollama
        environment:
            - TZ=America/Chicago
            - WATCHTOWER_HTTP_API_METRICS=true
            - WATCHTOWER_HTTP_API_TOKEN=token
            - WATCHTOWER_CLEANUP=true
            - WATCHTOWER_POLL_INTERVAL=3600
        labels:
            - "com.centurylinklabs.watchtower.scope=ollama"
        network_mode: service:ollama
        restart: always
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock

    ollama:
        image: ollama/ollama:latest
        container_name: ollama
        environment:
            - OLLAMA_KEEP_ALIVE=24h
        restart: always
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          capabilities: ["gpu"]
                          count: all
        volumes:
            - ollama:/root/.ollama

volumes:
    tailscale:
    ollama:
