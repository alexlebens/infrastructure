rook-ceph:
  crds:
    enabled: true
  csi:
    enableRbdDriver: true
    enableCephfsDriver: true
    enableCSIHostNetwork: true
    enableCephfsSnapshotter: true
    enableNFSSnapshotter: true
    enableRBDSnapshotter: true
    enablePluginSelinuxHostMount: false
    enableCSIEncryption: false
    enableMetadata: true
    provisionerReplicas: 3
    clusterName:
    logLevel: 0
    serviceMonitor:
      enabled: true
      interval: 5s
    csiAddons:
      enabled: false
    nfs:
      enabled: false
    topology:
      enabled: false
  enableDiscoveryDaemon: true
  scaleDownOperator: false
  monitoring:
    enabled: true

rook-ceph-cluster:
  operatorNamespace: rook-ceph
  toolbox:
    enabled: true
  monitoring:
    enabled: true
    createPrometheusRules: true
  pspEnable: false
  cephClusterSpec:
    cephVersion:
      # https://quay.io/repository/ceph/ceph?tab=tags
      image: quay.io/ceph/ceph:v18.2.2-20240311
      allowUnsupported: false
    dataDirHostPath: /var/lib/rook
    skipUpgradeChecks: false
    continueUpgradeAfterChecksEvenIfNotHealthy: false
    waitTimeoutForHealthyOSDInMinutes: 10
    mon:
      count: 3
      allowMultiplePerNode: false
    mgr:
      count: 1
      allowMultiplePerNode: false
      modules:
        - name: pg_autoscaler
          enabled: true
        - name: rook
          enabled: true
    dashboard:
      enabled: true
      ssl: false
    network:
      connections:
        encryption:
          enabled: true
        compression:
          enabled: true
        requireMsgr2: true
    crashCollector:
      disable: false
    logCollector:
      enabled: true
      periodicity: daily
      maxLogSize: 500M
    cleanupPolicy:
      confirmation: ""
    placement:
      all:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/rook-osd-node
                    operator: Exists
      mon:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/rook-control-node
                    operator: Exists
                  - key: node-role.kubernetes.io/control-plane
                    operator: Exists
        tolerations:
          - key: node-role.kubernetes.io/rook-control-node
            operator: Exists
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
    resources:
      mgr:
        limits:
          cpu: "1000m"
          memory: "1Gi"
        requests:
          cpu: "500m"
          memory: "1Gi"
      mon:
        limits:
          cpu: "2000m"
          memory: "2Gi"
        requests:
          cpu: "1000m"
          memory: "2Gi"
      osd:
        limits:
          cpu: "2000m"
          memory: "4Gi"
        requests:
          cpu: "1000m"
          memory: "4Gi"
      prepareosd:
        requests:
          cpu: "500m"
          memory: "50Mi"
    removeOSDsIfOutAndSafeToRemove: false
    storage:
      useAllNodes: true
      useAllDevices: true
      deviceFilter: sda
      config:
          osdsPerDevice: "1"
    csi:
      readAffinity:
        enabled: true
  ingress:
    dashboard:
      ingressClassName: traefik
      annotations:
        traefik.ingress.kubernetes.io/router.entrypoints: websecure
        traefik.ingress.kubernetes.io/router.tls: "true"
        cert-manager.io/cluster-issuer: letsencrypt-issuer
      host:
        name: ceph.alexlebens.net
        path: /
      tls:
        - secretName: rook-secret-tls
          hosts:
            - ceph.alexlebens.net
      rules:
        - host: ceph.alexlebens.net
          http:
            paths:
              - path: /
                pathType: Prefix
                backend:
                  service:
                    name: rook-ceph-mgr-dashboard
                    port:
                      name: http-dashboard
  cephBlockPools:
    - name: ceph-blockpool
      spec:
        failureDomain: host
        replicated:
          size: 3
        enableRBDStats: false
      storageClass:
        enabled: true
        name: ceph-block
        isDefault: true
        reclaimPolicy: Retain
        allowVolumeExpansion: true
        volumeBindingMode: "Immediate"
        parameters:
          imageFormat: "2"
          imageFeatures: layering,exclusive-lock,object-map,fast-diff
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/fstype: ext4
  cephBlockPoolsVolumeSnapshotClass:
    enabled: true
    name: ceph-blockpool-snapshot
    isDefault: false
    deletionPolicy: Retain
  cephFileSystems:
  cephFileSystemVolumeSnapshotClass:
    enabled: false
  cephObjectStores:
